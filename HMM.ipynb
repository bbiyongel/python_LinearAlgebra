{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model 을 배워보자 \n",
    "## ~= Dynamic clustering\n",
    "  \n",
    "  \n",
    "공간과 시간은 매우 다릅니다.  시간은 비가역적입니다. 이제부터 시간이라는 component를 넣어 어떻게 모델링 할지에 대해 알아보도록 하겠습니다.  \n",
    "\n",
    "### Time Series Data for GMM  \n",
    "기존 우리가 알고 있던 Gaussian Mixture Model 은 아래 그림과 같을것 입니다.  \n",
    "![](https://kr.mathworks.com/help/stats/clusterdatausingagaussianmixturemodelexample_01_ko_KR.png)\n",
    "\n",
    "그러면 이제는 이 모델에 시간이 추가된다면 어떻게 될지가 궁금할 것입니다.   \n",
    "  \n",
    "  \n",
    "예를 들면 주가지수를 생각해 보겠습니다. 어제의 주가 지수는 절대적이진 않겠지만 오늘의 주가지수에 영향을 분명히 줄것 입니다. 그런즉 관계가 있다고 볼 수 있습니다. 그러면 주가지수를 내부를 움직이는 동력은 무엇있을 것 입니다. 그 잠재적인 변수는 계속 지속될 수도 있고 , 어떠한 fundamental change가 있어 갑자기 변경될 수 있습니다.  \n",
    "  \n",
    "또 다른 예로는 우리가 쓰는 문장이 있습니다.  \n",
    "I love you 라는 문장이 있다면 you 목적어가 나오기 까지, I라는 주어를 결정하게 됩니다, 음 더 쉽게 말해 우리가 말할땐 어떠한 의도(목적어 you)가 반드시 있습니다. 그 의도를 맞추기 위한 어떠한 동력(문법)이 있다는 것 입니다.  \n",
    "  \n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile2.uf.tistory.com%2Fimage%2F9908AC405AD5FF93287F38)\n",
    "\n",
    "위 그림은 은닉된 state와 그에 따른 observation의 개념을 나타냅니다. HMM을 이용해 우리가 풀고자 하는 문제는 ( *관측가능한 것은 오직 y_t이며 또, y_t는 q_t에 종석적으로 발생할때) y_t의 sequence를 통해 q_t의 sequence를 추론 하는 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM의 구조\n",
    "HMM 은 <Q,Y,π,T,E> 라는 튜플로 정의됩니다, 각 요소들이 의매하는 내용은 아래와 같습니다. \n",
    "\n",
    "- Q={q1,q2,...,qN} - 은닉된 state들의 집합이다.\n",
    "- Y={y1,y2,...,yM} - 은닉된 state에서 발생할 수 있는 observation들의 집합이다.\n",
    "- π:RN - 초기 state가 qi일 확률을 나타내는 initial probability p(qi)의 집합이다.\n",
    "- A:RN×N - qi에서 qj로 이동할 확률을 나타내는 transition probability p(qj|qi)의 집합이다.\n",
    "- B:RN×M - qi에서 yj가 발생할 확률을 나타내는 emission probability p(yj|qi)의 집합이다.\n",
    "\n",
    "\n",
    "출처: https://untitledtblog.tistory.com/97 [Untitled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM의 동작 \n",
    "\n",
    "![[표 1] Initial probabilities와 transition probabilities](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F990C18415AD74F0224C353)\n",
    "[표 1] Initial probabilities와 transition probabilities\n",
    "\n",
    "\n",
    "![표2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F992C51405AD74F25027A1F)\n",
    "[표2] Emission probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표[1]을 통해 알 수 있는 정보는 전날 친구를 만났다면 오늘 또 친구를 만날 확률은 0.1 과 같다, 또 어제 공부를 했다면 오늘 게임을 확률은 0.3 이다. 와 같습니다.  \n",
    "\n",
    "표[2]는 오늘 공부를 했다면 돈을 쓸일이 없으므로 돈쓸 확률이 5퍼센트 밖에 안되는걸 확인 할 수 있습니다.   \n",
    "\n",
    "우리는 표[1],표[2]가 주어 졌을 때, HMM을 이용하여 두가지 사항을 추론할 수 있습니다.  \n",
    "\n",
    "- 지출 내역이 1 1 4 2 일 때, 이러한 지출 내역이 나타날 확률,\n",
    "- 지출 내역이 1 1 4 2 일 때, 이러한 지출 내역이 나타날 확률이 가장 큰 과거의 행동 추론\n",
    "\n",
    "위 같은 동작은 HMM 을 이용하여 조건부 확률을 계산하는 것과 같습니다. HMM을 구현할 떄는 이러한 두가지 추론 과정을 어떻게 구현할 것인지에 대해 고려 해야 합니다. \n",
    "\n",
    "- 1번. HMM의 parameter가 주어졌을 때, 주어진 observation이 나타날 확률 계산 \n",
    "- 2번. HMM의 parameter가 주어졌을 때, 주어진 observation이 나타날 확률이 가장 높은 state의 나열을 계산\n",
    "- 3번. 학습 데이터로부터 HMM의 parameter θ={π,A,B}를 학습\n",
    "\n",
    "1번과 2번의 문제는 dynamic programming 기반의 foward algorithm과 Viterbi(비터비) algorithm으로 해결 가능합니다.   \n",
    "HMM의 parameter를 학습시키는 마지막 문제는 주로 exception-maximization algorithm (EM algorithm)의 한 형태 Baum-Welch algorithm으로 해결합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foward Algorithm\n",
    "Forward Algorith은 j번째 상태에서 o1,…,ot가 나타날 전방확률 α를 구하는 기법입니다.\n",
    "\n",
    "#### Backward Probability\n",
    "전방확률 α와 반대 방향으로 계산한 것이 후방확률 β입니다. 다음과 같이 정의됩니다.  \n",
    "\n",
    "#### Viterbi algorithm\n",
    "vt(j)는 t번째 시점의 j번째 은닉상태의 비터비 확률을 가리킵니다. t번째 시점 j번째 상태의 backtrace btt(j)는 다음과 같이 정의됩니다.\n",
    "\n",
    "위 알고리즘들의 코드는 \n",
    "https://ratsgo.github.io/machine%20learning/2017/10/14/computeHMMs/\n",
    "여기서 확인 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward(self, sequence):\n",
    "    # sequence : O\n",
    "    # 아이스크림 소비 기록 시퀀스 [3, 1, 3]\n",
    "    sequence_length = len(sequence)\n",
    "    if sequence_length == 0:\n",
    "        return []\n",
    "\n",
    "    # Dynamic Programming\n",
    "    # 앞으로 중간 계산된 값들은 alpha라는 변수에 저장\n",
    "    alpha = [{}]\n",
    "\n",
    "    # 시작 지점의 alpha값 계산 후 alpha[0]에 저장\n",
    "    # alpha[0] = {'hot' : p(hot\\|start) * p(3\\|hot), \n",
    "    #             'cold' : p(cold\\|start) * p(3\\|cold)}\n",
    "    # p(3\\|cold) : emit_prob('cold', 3)\n",
    "    # sequence[0] : 3\n",
    "    for state in self._states:\n",
    "        alpha[0][state] = self.start_prob(state) * self.emit_prob(state, sequence[0])\n",
    "\n",
    "    # sequence의 두번째 값부터 마지막까지 likelihood 모두 계산\n",
    "    # index : 위 수식에서 t\n",
    "    for index in range(1, sequence_length):\n",
    "        alpha.append({})\n",
    "        for state_to in self._states:\n",
    "            prob = 0\n",
    "            for state_from in self._states:\n",
    "                # += : 위 수식에서 Σ\n",
    "                # alpha[index-1] : 위 수식에서 α_t-1\n",
    "                # state_from : 위 수식에서 i\n",
    "                # state_to : 위 수식에서 j\n",
    "                # trans_prob : 위 수식에서 a_ij\n",
    "                prob += alpha[index - 1][state_from] * \\\n",
    "                    self.trans_prob(state_from, state_to)\n",
    "            # emit_prob : 위 수식에서 b\n",
    "            # sequence[index] : 위 수식에서 o_t \n",
    "            alpha[index][state_to] = prob * self.emit_prob(state_to, sequence[index])\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _backward(self, sequence):\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\n",
    "        beta = [{}]\n",
    "        for state in self._states:\n",
    "            beta[0][state] = 1\n",
    "\n",
    "        for index in range(sequence_length - 1, 0, -1):\n",
    "            beta.insert(0, {})\n",
    "            for state_from in self._states:\n",
    "                prob = 0\n",
    "                for state_to in self._states:\n",
    "                    prob += beta[1][state_to] * \\\n",
    "                        self.trans_prob(state_from, state_to) * \\\n",
    "                        self.emit_prob(state_to, sequence[index])\n",
    "                beta[0][state_from] = prob\n",
    "\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(self, sequence):\n",
    "        # sequence : O\n",
    "        # sequence_length : T\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\t   \n",
    "        # delta : 비터비 확률 v\n",
    "        # Dynamic Programming : 중간 계산값 저장해 활용\n",
    "        delta = {}\n",
    "        \n",
    "        # 시작 지점의 delta값 계산\n",
    "        for state in self._states:\n",
    "            # start_prob(state) : p(cold\\|start) or p(hot\\|start)\n",
    "            # sequence[0] : 관측 시퀀스의 첫번째 요소, o_1, '3'\n",
    "            # emit_prob(state, sequence[0]) : p(3\\|cold) or p(3\\|hot)\n",
    "            delta[state] = self.start_prob(state) * self.emit_prob(state, sequence[0])\n",
    "            \n",
    "        # pre : backtrace\n",
    "        pre = []\n",
    "        \n",
    "        # sequence의 두번째 값부터 마지막까지 delta, backtrace 모두 계산\n",
    "        # index : 위 수식에서 t\n",
    "        for index in range(1, sequence_length):\n",
    "            # delta_bar : t번째 관측치의 비터비 확률들\n",
    "            # index가 거듭될수록 그 요소가 늘어남\n",
    "            # 다 돌면 sequence_length 길이\n",
    "            delta_bar = {}\n",
    "            # pre_state : t번째 관측치의 backtrace들\n",
    "            # index가 거듭될수록 그 요소가 늘어남\n",
    "            # 다 돌면 sequence_length 길이\n",
    "            pre_state = {}\n",
    "            for state_to in self._states:\n",
    "                max_prob = 0\n",
    "                max_state = None # backtrace 변수\n",
    "                for state_from in self._states:\n",
    "                    # state_from : 위 수식에서 i\n",
    "                    # state_to : 위 수식에서 j\n",
    "                    # delta[state_from] : 직전 상태의 비터비 확률(저장된 값 불러와 계산량 줄임)\n",
    "                    # trans_prob : 위 수식에서 a\n",
    "                    prob = delta[state_from] * self.trans_prob(state_from, state_to)\n",
    "                    # 비터비 확률 수식에서 i에 대해 최대값을 구하는데,\n",
    "                    # 방출확률 b는 i에 대해 무관하므로 최대값 연산에서 제외\n",
    "                    if prob > max_prob:\n",
    "                        # 최대값 저장 : 현재 상태의 비터비 확률\n",
    "                        max_prob = prob \n",
    "                        # 최대값의 위치 저장 : 현재 상태의 backtrace\n",
    "                        max_state = state_from \n",
    "                delta_bar[state_to] = max_prob * self.emit_prob(state_to, sequence[index])\n",
    "                pre_state[state_to] = max_state\n",
    "            # o_2까지의 비터비 확률을 구했다면 o_1 이전의 비터비 확률은 불필요\n",
    "            # o_2의 비터비 확률들의 모음인 delta_bar를 전체 delta에 덮어씌움\n",
    "            delta = delta_bar\n",
    "            # o_2까지의 backtrace를 구했다 하더라도 o_3은 달라질 수 있음\n",
    "            # pre에 pre_state를 append\n",
    "            pre.append(pre_state)\n",
    "\t    \n",
    "        # 전체 시퀀스를 대상으로 최대 비터비확률과\n",
    "        # 최대 비터비 확률을 내는 state 찾기\n",
    "        # 현재 delta에는 시퀀스의 마지막 요소(O_T)에 \n",
    "        # 해당하는 비터비 확률들이 저장돼 있기 때문\n",
    "        # (state로만 구분되어 있음)\n",
    "        max_state = None\n",
    "        max_prob = 0\n",
    "        for state in self._states:\n",
    "            if delta[state] > max_prob:\n",
    "                max_prob = delta[state]\n",
    "                max_state = state\n",
    "\n",
    "        if max_state is None:\n",
    "            return []\n",
    "\t   \n",
    "        # 최대 비터비 확률을 내는 state가 backtrace의 첫번째 요소\n",
    "        result = [max_state]\n",
    "        # index를 시퀀스의 역방향으로 후진하면서\n",
    "        for index in range(sequence_length - 1, 0, -1):\n",
    "            # index에 해당하는 max_state들을 뽑아내기\n",
    "            # 이는 저 위쪽에서 이미 max_state들을 저장해두었기 때문에 가능\n",
    "            max_state = pre[index - 1][max_state]\n",
    "            # 뽑아낸 max_state들을 result의 첫번째 위치에 저장\n",
    "            result.insert(0, max_state)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(self, sequence, smoothing=0):\n",
    "\n",
    "        length = len(sequence)\n",
    "        alpha = self._forward(sequence)\n",
    "        beta = self._backward(sequence)\n",
    "\n",
    "        gamma = []\n",
    "        for index in range(length):\n",
    "            prob_sum = 0\n",
    "            gamma.append({})\n",
    "            for state in self._states:\n",
    "                prob = alpha[index][state] * beta[index][state]\n",
    "                gamma[index][state] = prob\n",
    "                prob_sum += prob\n",
    "\n",
    "            if prob_sum == 0:\n",
    "                continue\n",
    "\n",
    "            for state in self._states:\n",
    "                gamma[index][state] /= prob_sum\n",
    "\n",
    "        xi = []\n",
    "        for index in range(length - 1):\n",
    "            prob_sum = 0\n",
    "            xi.append({})\n",
    "            for state_from in self._states:\n",
    "                xi[index][state_from] = {}\n",
    "                for state_to in self._states:\n",
    "                    prob = alpha[index][state_from] * beta[index + 1][state_to] * \\\n",
    "                        self.trans_prob(state_from, state_to) * \\\n",
    "                        self.emit_prob(state_to, sequence[index + 1])\n",
    "                    xi[index][state_from][state_to] = prob\n",
    "                    prob_sum += prob\n",
    "\n",
    "            if prob_sum == 0:\n",
    "                continue\n",
    "\n",
    "            for state_from in self._states:\n",
    "                for state_to in self._states:\n",
    "                    xi[index][state_from][state_to] /= prob_sum\n",
    "\n",
    "        states_number = len(self._states)\n",
    "        symbols_number = len(self._symbols)\n",
    "        for state in self._states:\n",
    "            # update start probability\n",
    "            self._start_prob[state] = \\\n",
    "                (smoothing + gamma[0][state]) / (1 + states_number * smoothing)\n",
    "\n",
    "            # update transition probability\n",
    "            gamma_sum = 0\n",
    "            for index in range(length - 1):\n",
    "                gamma_sum += gamma[index][state]\n",
    "\n",
    "            if gamma_sum > 0:\n",
    "                denominator = gamma_sum + states_number * smoothing\n",
    "                for state_to in self._states:\n",
    "                    xi_sum = 0\n",
    "                    for index in range(length - 1):\n",
    "                        xi_sum += xi[index][state][state_to]\n",
    "                    self._trans_prob[state][state_to] = (smoothing + xi_sum) / denominator\n",
    "            else:\n",
    "                for state_to in self._states:\n",
    "                    self._trans_prob[state][state_to] = 0\n",
    "\n",
    "            # update emission probability\n",
    "            gamma_sum += gamma[length - 1][state]\n",
    "            emit_gamma_sum = {}\n",
    "            for symbol in self._symbols:\n",
    "                emit_gamma_sum[symbol] = 0\n",
    "\n",
    "            for index in range(length):\n",
    "                emit_gamma_sum[sequence[index]] += gamma[index][state]\n",
    "\n",
    "            if gamma_sum > 0:\n",
    "                denominator = gamma_sum + symbols_number * smoothing\n",
    "                for symbol in self._symbols:\n",
    "                    self._emit_prob[state][symbol] = \\\n",
    "                        (smoothing + emit_gamma_sum[symbol]) / denominator\n",
    "            else:\n",
    "                for symbol in self._symbols:\n",
    "                    self._emit_prob[state][symbol] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmm\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/2f/b56e9bcd688fd68cc6fc79ec4ebc1614f5d4c65118c40d0f73edaca78e41/hmm-0.0.1.tar.gz\n",
      "Building wheels for collected packages: hmm\n",
      "  Building wheel for hmm (setup.py): started\n",
      "  Building wheel for hmm (setup.py): finished with status 'done'\n",
      "  Created wheel for hmm: filename=hmm-0.0.1-cp37-none-any.whl size=1877 sha256=022884a124316e28e8dad80aea83de11a4d38c434649b2e4fee4f0cfa9a284b5\n",
      "  Stored in directory: C:\\Users\\ashgh\\AppData\\Local\\pip\\Cache\\wheels\\33\\2f\\c4\\16c3de063dd3b32460ba94bb747635e3dce068eb3aad0a10ac\n",
      "Successfully built hmm\n",
      "Installing collected packages: hmm\n",
      "Successfully installed hmm-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logsumexp' from 'scipy.misc' (C:\\Users\\ashgh\\Anaconda3\\lib\\site-packages\\scipy\\misc\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c021478b92a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'hot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m start_prob = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hmm\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhmm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hmm\\hmm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'logsumexp' from 'scipy.misc' (C:\\Users\\ashgh\\Anaconda3\\lib\\site-packages\\scipy\\misc\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import hmm\n",
    "states = ('hot', 'cold')\n",
    "symbols = ('1', '2', '3')\n",
    "\n",
    "start_prob = {\n",
    "    'hot' : 0.8,\n",
    "    'cold' : 0.2\n",
    "}\n",
    "\n",
    "trans_prob = {\n",
    "    'hot': { 'hot' : 0.6, 'cold' : 0.4 },\n",
    "    'cold': { 'hot' : 0.4, 'cold' : 0.6 }\n",
    "}\n",
    "\n",
    "emit_prob = {\n",
    "    'hot': { '1' : 0.2, '2' : 0.4, '3' : 0.4 },\n",
    "    'cold': { '1' : 0.5, '2' : 0.4, '3' : 0.1 }\n",
    "}\n",
    "\n",
    "model = hmm.Model(states, symbols, start_prob, trans_prob, emit_prob)\n",
    "sequence = ['3', '1', '3']\n",
    "print(model.evaluate(sequence)) # Likelihood 계산\n",
    "print(model.decode(sequence)) # 최적상태열 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ㅔㅑㅔ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
